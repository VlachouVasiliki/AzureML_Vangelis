{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686789351
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc(\"font\", size=14)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Workspace, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686790216
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = '6ed9d167-b2e6-41b8-9500-35e6df64d9dc'\n",
    "resource_group = 'MLRG'\n",
    "workspace_name = 'erbbimlws'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(workspace = workspace, name = \"LightGBM_on_Primary_Bank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.start_logging(snapshot_directory=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686854663
    }
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.get_by_name(workspace, name='Primary_Bank')\n",
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686855104
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', None) #display all columns\n",
    "#pd.reset_option(“max_columns”) #to return to default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686855348
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686855549
    }
   },
   "outputs": [],
   "source": [
    "df['New_Primary_Bank_Flag'].value_counts().plot(kind = 'pie',y = 'New_Primary_Bank_Flag',figsize=(5, 5),title = 'New_Primary_Bank_Flag',autopct='%1.1f%%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686855695
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['Customer_ID','Year','Month','Primary_Bank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686855853
    }
   },
   "outputs": [],
   "source": [
    "def binF(x):\n",
    "    if x is False:\n",
    "        z = 0\n",
    "    elif math.isnan(x):\n",
    "        z = 0\n",
    "    else:\n",
    "        z =1\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686856111
    }
   },
   "outputs": [],
   "source": [
    "df['New_Primary_Bank_Flag'] = df['New_Primary_Bank_Flag'].apply(binF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686856332
    }
   },
   "outputs": [],
   "source": [
    "#dummy variables\n",
    "for col in df.columns:       \n",
    "       if df[col].dtypes=='object':\n",
    "            df.drop(columns=col, inplace = True)\n",
    "            #df = pd.get_dummies(df, prefix=col + '_', columns=[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686856560
    }
   },
   "outputs": [],
   "source": [
    "for col in df.columns:       \n",
    "       if df[col].dtypes=='datetime64[ns]':\n",
    "            df = df.drop(columns = col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_gt(x):\n",
    "    x = x.replace('<=','le ')\n",
    "    x = x.replace('>=','ge')\n",
    "    x = x.replace('>','gt ')\n",
    "    x = x.replace('<','lt ')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [replace_gt(x) for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686856707
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.loc[:,df.columns !='New_Primary_Bank_Flag'].fillna(0), df['New_Primary_Bank_Flag'].fillna(0), test_size=0.25, random_state=0)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(df.loc[:,important_features].fillna(0), df['New_Primary_Bank_Flag'].fillna(0), test_size=0.25, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth':5,'colsample_bytree':0.5,'min_data_in_leaf':1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_table('Parameters', parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686856872
    }
   },
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686914787
    }
   },
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,early_stopping_rounds =10,\\\n",
    "            eval_metric = 'aucpr', eval_set = [(x_test,y_test)],verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686914952
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_train,  model.predict(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686915214
    }
   },
   "outputs": [],
   "source": [
    "print('Accuracy of Light GBoost classifier on train set: {:.4f}'.format(model.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log('Accuracy of Light GBoost classifier on train set:','{:.4f}'.format(model.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686915525
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,  model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686915667
    }
   },
   "outputs": [],
   "source": [
    "print('Accuracy of Light GBoost classifier on test set: {:.4f}'.format(model.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log('Accuracy of Light GBoost classifier on test set:','{:.4f}'.format(model.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686915956
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "cm = plot_confusion_matrix(model,x_train,y_train,display_labels = ['Non Primary', 'Primary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.figure_.savefig('images/Confusion_Matrix_train.jpg')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_image('Confusion Matrix (train)','images/Confusion_Matrix_train.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = plot_confusion_matrix(model,x_test,y_test,display_labels = ['Non Primary', 'Primary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.figure_.savefig('images/Confusion_Matrix_test.jpg')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log_image('Confusion Matrix (test)','images/Confusion_Matrix_test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(y_test, model.predict(x_test))\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, model.predict_proba(x_test)[:,1])\n",
    "auc_test = roc_auc = auc(fpr_test, tpr_test)\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_train, model.predict(x_train))\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, model.predict_proba(x_train)[:,1])\n",
    "auc_train = roc_auc = auc(fpr_train, tpr_train)\n",
    "cm =plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, label='Light GBoost train (area = %0.2f)' % auc_train)\n",
    "plt.plot(fpr_test, tpr_test, label='Light GBoost test (area = %0.2f)' % auc_test)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.savefig('images/ROC.jpg')\n",
    "plt.close()\n",
    "run.log_image('ROC','images/ROC.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686916612
    }
   },
   "outputs": [],
   "source": [
    "#explainer = shap.TreeExplainer(model, x_train)\n",
    "explainer = shap.Explainer(model, x_train)\n",
    "shap_values = explainer.shap_values(x_train,check_additivity=False)\n",
    "x_train_array = x_train#.to_numpy() # we need to pass a dense version for the plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686917365
    }
   },
   "outputs": [],
   "source": [
    "ss= plt.figure()\n",
    "shap.summary_plot(shap_values, x_train_array,x_train.columns,max_display = 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.savefig('images/SHAP_Summary.jpg',bbox_inches='tight')\n",
    "plt.close()\n",
    "run.log_image('SHAP - Summary','images/SHAP_Summary.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1642686917736
    }
   },
   "outputs": [],
   "source": [
    "important_features = pd.DataFrame(model.feature_importances_,x_train.columns,columns =['Importance'])\\\n",
    "    .sort_values(by='Importance', ascending = False).head(20).index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = plt.figure()\n",
    "shap.plots.beeswarm(explainer(x_train),max_display = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs.savefig('images/SHAP_Beeswarm.jpg',bbox_inches='tight')\n",
    "plt.close()\n",
    "run.log_image('SHAP - Beeswarm','images/SHAP_Beeswarm.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.complete()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
