{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!python -m spacy download el_core_news_sm\r\n",
        "#!pip install pyarrow --upgrade"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614245653690
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import el_core_news_sm\n",
        "import string\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1614245692813
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.el import GreekLemmatizer"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1614245695217
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.el import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1614245695392
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = el_core_news_sm.load()"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1614245697054
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = GreekLemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1614245697229
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = re.compile('δεν απαντ.{1,3}\\s{0,1}',re.IGNORECASE)\r\n",
        "p2 = re.compile('\\sδα\\s',re.IGNORECASE)\r\n",
        "p3 = re.compile('δε.{0,1}\\s.{0,3}\\s{0,1}βρ.{1,2}κ.\\s{0,1}',re.IGNORECASE)\r\n",
        "p4 = re.compile('[^\\d]?\\d{10}')\r\n",
        "p5 = re.compile('[^\\d]?\\d{18}|[^\\d]\\d{20}')\r\n",
        "p6 = re.compile('δε[ ν] {0,1} (επιθυμ[α-ω]{2,4}?|ηθελ[α-ω]{1,3}?|θελ[α-ω]{1,4}|.{0,10}ενδιαφερ[α-ω]{2,4})',re.IGNORECASE)\r\n",
        "p7 = re.compile('δε[ ν] {0,1} (μπορ[α-ω]{2,5}|.εχει)',re.IGNORECASE)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614245697321
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadStopWords():\n",
        "    sWords = open('stopWords.txt','r',encoding='utf-8')\n",
        "    sw = set(sWords.read().split('\\n'))\n",
        "    #sw = sw.remove('μη')\n",
        "    sWords.close()\n",
        "    return sw"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1614245697495
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replaceTerm(text):\r\n",
        "    text = p5.sub(' λογαριασμός ',text)\r\n",
        "    text = p4.sub(' τηλεφωνο ',text)\r\n",
        "    text = p6.sub(' δενθελειδενενδιαφερεται ',text)\r\n",
        "    text = p7.sub(' δενεχειδενμπορει ',text)\r\n",
        "    text = text.replace('-banking','banking')\r\n",
        "    text = text.replace('v banking','vbanking')\r\n",
        "    text = text.replace('e banking','ebanking')\r\n",
        "    text = text.replace('follow up','followup')\r\n",
        "    text = text.replace('safe drive','safedrive')\r\n",
        "    text = text.replace('safe pocket','safepocket')\r\n",
        "    text = text.replace('sweet home','sweethome')\r\n",
        "    text = text.replace('credit card','creditcard')\r\n",
        "    text = text.replace('debit card','debitcard')\r\n",
        "    text = text.replace('life cycle','lifecycle')\r\n",
        "    text = text.replace('π/κ','πκ')\r\n",
        "    text = text.replace('α/κ','ακ')\r\n",
        "    text = text.replace('δ/α','δεναπαντα ')\r\n",
        "    text = p1.sub(' δεναπαντα ',text)\r\n",
        "    text = p2.sub(' δεναπαντα ',text)\r\n",
        "    text = p3.sub(' δεντονβρηκα ',text)\r\n",
        "    return text\r\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614245697581
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sw = nlp.Defaults.stop_words\n",
        "#sw = sw|{'εχω','απο','ωστε'}\n",
        "sw = loadStopWords()\n",
        "def remove_ton(text):\n",
        "    diction = {'ά':'α','έ':'ε','ί':'ι','ό':'ο','ώ':'ω','ύ':'υ'}\n",
        "    for key in diction.keys():\n",
        "        text = text.replace(key, diction[key])\n",
        "    return text   \n",
        "def clean_text(text):\n",
        "     #text to string\n",
        "    text = str(text).lower()\n",
        "    text = replaceTerm(text)\n",
        "   # tokenize text and remove puncutation\n",
        "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
        "    # lower text\n",
        "    text = [remove_ton(x) for x in text]\n",
        "    # remove stop words\n",
        "    text = [x for x in text if x not in sw]\n",
        " \n",
        "    #remove quotes\n",
        "    text = [x.replace('quot;','').replace('&quot','') for x in text if x not in ['quot','amp']]\n",
        "    # remove words that contain numbers\n",
        "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
        "    # remove empty tokens\n",
        "    text = [t for t in text if len(t) > 0]\n",
        "    # remove amp & quot\n",
        "    text = [x for x in text if x not in ['quot','amp']]\n",
        "    # remove words with only one letter\n",
        "    text = \" \".join([t for t in text if len(t) > 1])\n",
        "    # lemmatize text\n",
        "    text = \" \".join([lemmatizer(t.text,t.pos_)[0] for t in nlp(text)])\n",
        "   \n",
        "    return(text)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1614245697772
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def correct(x,corDict):\r\n",
        "    if x in corDict.keys():\r\n",
        "        y = corDict[x]\r\n",
        "    else:\r\n",
        "        y = x\r\n",
        "    return y    "
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614245697878
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fileNum = '02'"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614245697972
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# azureml-core of version 1.0.72 or higher is required\n",
        "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "subscription_id = '6ed9d167-b2e6-41b8-9500-35e6df64d9dc'\n",
        "resource_group = 'MLRG'\n",
        "workspace_name = 'erbbimlws'\n",
        "\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
        "\n",
        "dataset = Dataset.get_by_name(workspace, name='LinkComments{0}'.format(fileNum))\n",
        "df = dataset.to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/_dataframereader.py:238: UserWarning: Using alternate reader. Inconsistent or mixed schemas detected across partitions: partition had different number of columns. The first partition has 5 columns. Found partition has 2 columns.\n",
            "First partition columns (ordered): ['CON_ROW_ID', 'CON_COMMENTS', 'Column3', 'Column4', 'Column5']\n",
            "Found Partition has columns (ordered): ['CON_ROW_ID', 'CON_COMMENTS']\n",
            "  warnings.warn('Using alternate reader. ' + reason)\n",
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/_dataframereader.py:171: UserWarning: Please install pyarrow>=0.16.0 for improved performance of to_pandas_dataframe. You can ensure the correct version is installed by running: pip install pyarrow>=0.16.0 --upgrade\n",
            "  warnings.warn('Please install pyarrow>=0.16.0 for improved performance of to_pandas_dataframe. '\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1614245722092
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['CON_ROW_ID','CON_COMMENTS']]"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1614245722358
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df.columns\r\n",
        "df.head()\r\n",
        "df.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "(167960, 2)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614245722547
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokenized'] = df['CON_COMMENTS'].apply(clean_text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1614247397661
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df.to_excel('LinkCommentssample_2.xlsx')\r\n",
        "#df.head(1000)\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1614247397859
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.fillna('N/A')"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1614247398157
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df[df['tokenized'].str.contains(' χρονι ') ]#[~df['tokenized'].str.contains('banking') ]"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614247398348
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(min_df = 1000,ngram_range = (1,2))"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1614247398437
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_result = tfidf.fit_transform(df['tokenized']).toarray()"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1614247406462
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1614247406630
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_df.columns = [str(x) for x in tfidf_df.columns]"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1614247406787
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = pd.concat([df[['CON_ROW_ID']],tfidf_df],axis=1).melt(id_vars=['CON_ROW_ID'],value_vars = tfidf_df.columns).dropna()"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1614247417000
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f[df_f['value']>0]"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1614247417327
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "(583357, 3)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614247417511
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f['variable'].value_counts().to_excel('tokenlist.xlsx')"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614247421024
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corDict = dict(pd.read_excel(\"corTokens.xls\").to_dict(\"split\")['data'])"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614247421371
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f['token'] = df_f['variable'].apply(lambda x : correct(x,corDict))"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614247421765
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f[df_f['token'] !='rmv']"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614247422001
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f.fillna('N/A')"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614247422166
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f.sort_values(['CON_ROW_ID','token'])"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614247422759
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f['token_c'] = df_f['token']"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614247422924
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = df_f.shape[0]"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614247423013
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f.head(100)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "          CON_ROW_ID   variable     value              token  \\\n19483362  54154396.0       ληξη  0.468954               ληξη   \n27881362  54154396.0    προταση  0.514935            προταση   \n31408522  54154396.0        τηλ  0.514448           τηλεφωνο   \n4870843   55574534.0         ακ  0.500260  αμοιβαιο κεφαλαιο   \n17803763  55574534.0   καταβολη  0.612434           καταβολη   \n...              ...        ...       ...                ...   \n839835    59831182.0   ebanking  0.347869           ebanking   \n2855355   59831182.0   personal  0.396849           personal   \n14108675  59831182.0  επιστροφη  0.399884          επιστροφη   \n15956235  59831182.0       θεση  0.346223               θεση   \n19483395  59831182.0       ληξη  0.297820               ληξη   \n\n                    token_c  \n19483362               ληξη  \n27881362            προταση  \n31408522           τηλεφωνο  \n4870843   αμοιβαιο κεφαλαιο  \n17803763           καταβολη  \n...                     ...  \n839835             ebanking  \n2855355            personal  \n14108675          επιστροφη  \n15956235               θεση  \n19483395               ληξη  \n\n[100 rows x 5 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CON_ROW_ID</th>\n      <th>variable</th>\n      <th>value</th>\n      <th>token</th>\n      <th>token_c</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19483362</th>\n      <td>54154396.0</td>\n      <td>ληξη</td>\n      <td>0.468954</td>\n      <td>ληξη</td>\n      <td>ληξη</td>\n    </tr>\n    <tr>\n      <th>27881362</th>\n      <td>54154396.0</td>\n      <td>προταση</td>\n      <td>0.514935</td>\n      <td>προταση</td>\n      <td>προταση</td>\n    </tr>\n    <tr>\n      <th>31408522</th>\n      <td>54154396.0</td>\n      <td>τηλ</td>\n      <td>0.514448</td>\n      <td>τηλεφωνο</td>\n      <td>τηλεφωνο</td>\n    </tr>\n    <tr>\n      <th>4870843</th>\n      <td>55574534.0</td>\n      <td>ακ</td>\n      <td>0.500260</td>\n      <td>αμοιβαιο κεφαλαιο</td>\n      <td>αμοιβαιο κεφαλαιο</td>\n    </tr>\n    <tr>\n      <th>17803763</th>\n      <td>55574534.0</td>\n      <td>καταβολη</td>\n      <td>0.612434</td>\n      <td>καταβολη</td>\n      <td>καταβολη</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>839835</th>\n      <td>59831182.0</td>\n      <td>ebanking</td>\n      <td>0.347869</td>\n      <td>ebanking</td>\n      <td>ebanking</td>\n    </tr>\n    <tr>\n      <th>2855355</th>\n      <td>59831182.0</td>\n      <td>personal</td>\n      <td>0.396849</td>\n      <td>personal</td>\n      <td>personal</td>\n    </tr>\n    <tr>\n      <th>14108675</th>\n      <td>59831182.0</td>\n      <td>επιστροφη</td>\n      <td>0.399884</td>\n      <td>επιστροφη</td>\n      <td>επιστροφη</td>\n    </tr>\n    <tr>\n      <th>15956235</th>\n      <td>59831182.0</td>\n      <td>θεση</td>\n      <td>0.346223</td>\n      <td>θεση</td>\n      <td>θεση</td>\n    </tr>\n    <tr>\n      <th>19483395</th>\n      <td>59831182.0</td>\n      <td>ληξη</td>\n      <td>0.297820</td>\n      <td>ληξη</td>\n      <td>ληξη</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 5 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 35,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614247423303
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for i in range(0,n-1):\r\n",
        "#    if df_f['CON_ROW_ID'].iloc[i] == df_f['CON_ROW_ID'].iloc[i+1]:\r\n",
        "#        #print(df_f['token_c'].iloc[i],type(df_f['token_c'].iloc[i]),type(df_f['token_c'].iloc[i+1]),df_f['token_c'].iloc[i+1])\r\n",
        "#        if df_f['token_c'].iloc[i] in df_f['token_c'].iloc[i+1]:\r\n",
        "#            df_f.iloc[i,4] = df_f['token_c'].iloc[i+1]\r\n",
        "        \r\n",
        "            "
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614247423394
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f[['CON_ROW_ID','token_c']].drop_duplicates()"
      ],
      "outputs": [],
      "execution_count": 37,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614247423566
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_f.head()\r\n",
        "#df_f.shape\r\n",
        "#df_f['token_c'].value_counts().to_excel('tokens_c.xlsx')"
      ],
      "outputs": [],
      "execution_count": 38,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614247423747
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f.to_csv('comments_tokens_{0}.txt'.format(fileNum),sep ='\\t',line_terminator='\\r\\n',index = False)"
      ],
      "outputs": [],
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614247425835
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_f.to_excel('vBanking_tokens_s.xlsx',index = False)\n",
        "#df_f[df_f['value']>0].to_excel('D://Downloads//comments_tokens.xlsx')\n",
        "#df.to_excel('D://Downloads//comments_cleaned.xlsx')"
      ],
      "outputs": [],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1614247426004
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_f[df_f['CON_ROW_ID'] ==60427536]\r\n"
      ],
      "outputs": [],
      "execution_count": 41,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614247426088
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}