{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-pipelines"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1635928342063
        }
      },
      "id": "lasting-literacy"
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace, Datastore\n",
        "from azureml.data import OutputFileDatasetConfig\n",
        "\n",
        "\n",
        "ws = Workspace(subscription_id = '6ed9d167-b2e6-41b8-9500-35e6df64d9dc',\n",
        "                resource_group = 'MLRG',\n",
        "                workspace_name = 'erbbimlws'\n",
        "              )"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1635928342682
        }
      },
      "id": "departmental-diagnosis"
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1635928342816
        }
      },
      "id": "interested-region"
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.graph import PipelineParameter\n",
        "\n",
        "pipeline_param = PipelineParameter(\n",
        "  name=\"pipeline_arg\",\n",
        "  default_value=10)"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1635928342980
        }
      },
      "id": "prescribed-flavor"
    },
    {
      "cell_type": "code",
      "source": [
        "compute_name = \"vkontogCompute\""
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1635928343098
        }
      },
      "id": "advisory-violin"
    },
    {
      "cell_type": "code",
      "source": [
        "# Default datastore \n",
        "datastore= Datastore(ws, \"workspaceblobstore\")\n",
        "#datastore= Datastore(ws, \"workspacefilestore\")"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1635928343267
        }
      },
      "id": "billion-capture"
    },
    {
      "cell_type": "code",
      "source": [
        "if compute_name in ws.compute_targets:\n",
        "    compute_target = ws.compute_targets[compute_name]\n",
        "    if compute_target and type(compute_target) is AmlCompute:\n",
        "        print('Found compute target: ' + compute_name)\n",
        "else:\n",
        "    print('Please set up a proper compute')\n"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1635928343492
        }
      },
      "id": "seeing-amateur"
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import RunConfiguration\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core import Environment \n",
        "\n",
        "\n",
        "aml_run_config = RunConfiguration()\n",
        "# Use just-specified compute target (\"cpu-cluster\")\n",
        "aml_run_config.target = compute_target"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1635928343620
        }
      },
      "id": "czech-meter"
    },
    {
      "cell_type": "code",
      "source": [
        "aml_run_config.environment.python.conda_dependencies = CondaDependencies.create(\n",
        "    conda_packages=['pandas','scikit-learn'], \n",
        "    pip_packages=['azureml-sdk', 'azureml-dataset-runtime[fuse,pandas]',' pyarrow','openpyxl','xlrd','spacy'], \n",
        "    pin_sdk_version=False)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1635928343761
        }
      },
      "id": "electronic-philosophy"
    },
    {
      "cell_type": "code",
      "source": [
        "output_data = OutputFileDatasetConfig(destination = (datastore, 'UI/NPL/tokens'))\n",
        "output_data_dataset = output_data.register_on_complete(name = 'exported_tokens')"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1635928343889
        }
      },
      "id": "arabic-nomination"
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data import OutputFileDatasetConfig\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "\n",
        "#dataprep_step0 = PythonScriptStep(\n",
        "#    name=\"Spacy_NLP_v0\", \n",
        "#    script_name=\"./Text_Mining_withSpacy/pipTest.py\", \n",
        "#    compute_target=compute_target, \n",
        "#    runconfig=aml_run_config,\n",
        "#    allow_reuse=True\n",
        "#)\n",
        "\n",
        "dataprep_step1 = PythonScriptStep(\n",
        "    name=\"Spacy_NLP_v1\", \n",
        "    script_name=\"./Spacy_NLP_on_LinkComments_Daily.py\", \n",
        "    compute_target=compute_target, \n",
        "    runconfig=aml_run_config,\n",
        "    allow_reuse=False,\n",
        "    arguments=[ \"--param1\", pipeline_param,\"--ws\",ws]\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1635928344012
        }
      },
      "id": "armed-robin"
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.core import Experiment\n",
        "\n",
        "pipeline = Pipeline(ws, [dataprep_step1])\n",
        "\n",
        "experiment = Experiment(workspace=ws, name='Link_Comments')\n",
        "\n",
        "azureml._restclient.snapshots_client.SNAPSHOT_MAX_SIZE_BYTES = 1000000000\n",
        "\n",
        "run = experiment.submit(pipeline, show_output=True)\n",
        "run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step Spacy_NLP_v1 [62833740][0ba18779-dca6-444c-b92e-f4b367fa43ba], (This step will run and generate new outputs)\nSubmitted PipelineRun 1d9e9db7-9b1c-4346-ba19-640c51d15ab4\nLink to Azure Machine Learning Portal: https://ml.azure.com/experiments/Link_Comments/runs/1d9e9db7-9b1c-4346-ba19-640c51d15ab4?wsid=/subscriptions/6ed9d167-b2e6-41b8-9500-35e6df64d9dc/resourcegroups/MLRG/workspaces/erbbimlws\nPipelineRunId: 1d9e9db7-9b1c-4346-ba19-640c51d15ab4\nLink to Azure Machine Learning Portal: https://ml.azure.com/experiments/Link_Comments/runs/1d9e9db7-9b1c-4346-ba19-640c51d15ab4?wsid=/subscriptions/6ed9d167-b2e6-41b8-9500-35e6df64d9dc/resourcegroups/MLRG/workspaces/erbbimlws\nPipelineRun Status: NotStarted\nPipelineRun Status: Running\n\n\nStepRunId: 5987c920-00d6-4386-b163-df1564f1cdd1\nLink to Azure Machine Learning Portal: https://ml.azure.com/experiments/Link_Comments/runs/5987c920-00d6-4386-b163-df1564f1cdd1?wsid=/subscriptions/6ed9d167-b2e6-41b8-9500-35e6df64d9dc/resourcegroups/MLRG/workspaces/erbbimlws\nStepRun( Spacy_NLP_v1 ) Status: NotStarted\nStepRun( Spacy_NLP_v1 ) Status: Running\n\nStreaming azureml-logs/55_azureml-execution-tvmps_5f6cbc88c0540ab8f59e613a430e25a0a648f8cc0cbb0c7dd052522cfdbd358a_d.txt\n========================================================================================================================\n2021-11-03T08:41:18Z Running following command: /bin/bash -c sudo blobfuse /mnt/resource/batch/tasks/shared/LS_root/jobs/erbbimlws/azureml/5987c920-00d6-4386-b163-df1564f1cdd1/mounts/workspaceblobstore --tmp-path=/mnt/resource/batch/tasks/shared/LS_root/jobs/erbbimlws/azureml/5987c920-00d6-4386-b163-df1564f1cdd1/caches/workspaceblobstore -o ro --file-cache-timeout-in-seconds=1000000 --cache-size-mb=4714 -o nonempty -o allow_other --config-file=/mnt/resource/batch/tasks/shared/LS_root/jobs/erbbimlws/azureml/5987c920-00d6-4386-b163-df1564f1cdd1/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n2021-11-03T08:41:18Z Successfully mounted a/an Blobfuse File System at /mnt/resource/batch/tasks/shared/LS_root/jobs/erbbimlws/azureml/5987c920-00d6-4386-b163-df1564f1cdd1/mounts/workspaceblobstore\n2021-11-03T08:41:18Z The vmsize standard_d2s_v3 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-11-03T08:41:18Z Starting output-watcher...\n2021-11-03T08:41:18Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n2021-11-03T08:41:20Z Executing 'Copy ACR Details file' on 10.0.0.5\n2021-11-03T08:41:20Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n>>>   \n>>>   \nLogin Succeeded\nUsing default tag: latest\nlatest: Pulling from azureml/azureml_7dff877600321494840f842e11b9b75e\nDigest: sha256:ed104785d1f5bd3e4a56a054358f98f75142a5014a8a5f0788bd075fafabc74d\nStatus: Image is up to date for 0dc3187d2e8243069a1c6d758da287e2.azurecr.io/azureml/azureml_7dff877600321494840f842e11b9b75e:latest\n0dc3187d2e8243069a1c6d758da287e2.azurecr.io/azureml/azureml_7dff877600321494840f842e11b9b75e:latest\n2021-11-03T08:41:20Z The vmsize standard_d2s_v3 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n2021-11-03T08:41:20Z Check if container 5987c920-00d6-4386-b163-df1564f1cdd1 already exist exited with 0, \n\nec87ddec22e9a3337aeabfc52620348ad1866cf0a3925d6a4f7d655a8f6b1bb7\n2021-11-03T08:41:21Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n2021-11-03T08:41:21Z containerSetup task cmd: [/mnt/resource/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-3449e7029ed18df00725e374bc7c32c0-e247508d0c939679-01 -sshRequired=false] \n2021/11/03 08:41:21 Got JobInfoJson from env\n2021/11/03 08:41:21 Starting App Insight Logger for task:  containerSetup\n2021/11/03 08:41:21 Version: 3.0.01755.0003 Branch: .SourceBranch Commit: 66828d8\n2021/11/03 08:41:21 Entered ContainerSetupTask - Preparing infiniband\n2021/11/03 08:41:21 Starting infiniband setup\n2021/11/03 08:41:21 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n\n2021/11/03 08:41:21 Returning Python Version as 3.6\n2021-11-03T08:41:21Z VMSize: standard_d2s_v3, Host: ubuntu, Container: ubuntu-16.04\n2021-11-03T08:41:21Z Not setting up Infiniband in Container\n2021/11/03 08:41:21 VMSize: standard_d2s_v3, Host: ubuntu, Container: ubuntu-16.04\n2021/11/03 08:41:21 VMSize: standard_d2s_v3, Host: ubuntu, Container: ubuntu-16.04\n2021/11/03 08:41:21 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n2021/11/03 08:41:21 Not setting up Infiniband in Container\n2021/11/03 08:41:21 Not setting up Infiniband in Container\n2021/11/03 08:41:21 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n\n2021/11/03 08:41:21 Returning Python Version as 3.6\n2021/11/03 08:41:21 sshd inside container not required for job, skipping setup.\n2021/11/03 08:41:21 All App Insights Logs was sent successfully or the close timeout of 10 was reached\n2021/11/03 08:41:21 App Insight Client has already been closed\n2021/11/03 08:41:21 Not exporting to RunHistory as the exporter is either stopped or there is no data.\nStopped: false\nOriginalData: 1\nFilteredData: 0.\n2021-11-03T08:41:21Z Starting docker container succeeded.\n\nStreaming azureml-logs/75_job_post-tvmps_5f6cbc88c0540ab8f59e613a430e25a0a648f8cc0cbb0c7dd052522cfdbd358a_d.txt\n===============================================================================================================\n[2021-11-03T08:41:43.585665] Entering job release\nFailure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (pyarrow 5.0.0 (/azureml-envs/azureml_42c6d77fb1beb849dc157c8a40d1c37e/lib/python3.6/site-packages), Requirement.parse('pyarrow<4.0.0,>=0.17.0'), {'azureml-dataset-runtime'}).\n[2021-11-03T08:41:44.916396] Starting job release\n[2021-11-03T08:41:44.917224] Logging experiment finalizing status in history service.\n[2021-11-03T08:41:44.917562] job release stage : upload_datastore starting...\nStarting the daemon thread to refresh tokens in background for process with pid = 136\n[2021-11-03T08:41:44.918023] job release stage : start importing azureml.history._tracking in run_history_release.\n[2021-11-03T08:41:44.918418] job release stage : copy_batchai_cached_logs starting...\n[2021-11-03T08:41:44.918475] job release stage : copy_batchai_cached_logs completed...\n[2021-11-03T08:41:44.919006] job release stage : execute_job_release starting...\n[2021-11-03T08:41:44.920567] Entering context manager injector.\n[2021-11-03T08:41:44.925958] job release stage : upload_datastore completed...\n[2021-11-03T08:41:45.040169] job release stage : send_run_telemetry starting...\n[2021-11-03T08:41:45.081213] get vm size and vm region successfully.\n[2021-11-03T08:41:45.114135] get compute meta data successfully.\n[2021-11-03T08:41:45.230165] job release stage : execute_job_release completed...\n[2021-11-03T08:41:45.419574] post artifact meta request successfully.\n[2021-11-03T08:41:45.461631] upload compute record artifact successfully.\n[2021-11-03T08:41:45.461758] job release stage : send_run_telemetry completed...\n[2021-11-03T08:41:45.462317] Job release is complete\n\nStepRun(Spacy_NLP_v1) Execution Summary\n========================================\nStepRun( Spacy_NLP_v1 ) Status: Failed\n\nWarnings:\n{\n  \"error\": {\n    \"code\": \"UserError\",\n    \"severity\": null,\n    \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n    \"messageFormat\": \"{Message}\",\n    \"messageParameters\": {\n      \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n    },\n    \"referenceCode\": null,\n    \"detailsUri\": null,\n    \"target\": null,\n    \"details\": [],\n    \"innerError\": {\n      \"code\": \"UserTrainingScriptFailed\",\n      \"innerError\": null\n    },\n    \"debugInfo\": null,\n    \"additionalInfo\": null\n  },\n  \"correlation\": {\n    \"operation\": \"29af3ebb2593514786eb22ebb2a8a2df\",\n    \"request\": \"73a4f323dfcf187b\"\n  },\n  \"environment\": \"westeurope\",\n  \"location\": \"westeurope\",\n  \"time\": \"2021-11-03T08:42:06.6017605+00:00\",\n  \"componentName\": \"globaljobdispatcher\"\n}\n"
        },
        {
          "output_type": "error",
          "ename": "ActivityFailedException",
          "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with SyntaxError: invalid syntax (Spacy_NLP_on_LinkComments_Daily.py, line 249)\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with SyntaxError: invalid syntax (Spacy_NLP_on_LinkComments_Daily.py, line 249)\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-bc10f8fdfebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    293\u001b[0m                             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                                 step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n\u001b[0;32m--> 295\u001b[0;31m                                                              raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    296\u001b[0m                             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                                 \u001b[0;31m# If there are package conflicts in the user's environment, the run rehydration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n\u001b[0;32m--> 737\u001b[0;31m                                                raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The output streaming for the run interrupted.\\n\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"User program failed with SyntaxError: invalid syntax (Spacy_NLP_on_LinkComments_Daily.py, line 249)\",\n        \"messageParameters\": {},\n        \"detailsUri\": \"https://aka.ms/azureml-run-troubleshooting\",\n        \"details\": []\n    },\n    \"time\": \"0001-01-01T00:00:00.000Z\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"User program failed with SyntaxError: invalid syntax (Spacy_NLP_on_LinkComments_Daily.py, line 249)\\\",\\n        \\\"messageParameters\\\": {},\\n        \\\"detailsUri\\\": \\\"https://aka.ms/azureml-run-troubleshooting\\\",\\n        \\\"details\\\": []\\n    },\\n    \\\"time\\\": \\\"0001-01-01T00:00:00.000Z\\\"\\n}\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 27,
      "metadata": {
        "scrolled": false,
        "gather": {
          "logged": 1635927471765
        }
      },
      "id": "together-liabilities"
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = run.publish_pipeline(\n",
        "     name=\"NLP_Pipeline_Daily\",\n",
        "     description=\"Daily NLP pipeline\",\n",
        "     version=\"1.0\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1635927472253
        }
      },
      "id": "large-accident"
    },
    {
      "cell_type": "code",
      "source": [
        "#from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "#interactive_auth = InteractiveLoginAuthentication()\n",
        "#auth_header = interactive_auth.get_authentication_header()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1635927472372
        }
      },
      "id": "earlier-minority"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}