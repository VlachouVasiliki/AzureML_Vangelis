{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!python -m spacy download el_core_news_sm"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1612186233438
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import el_core_news_sm\n",
        "import string\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1612186235804
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.el import GreekLemmatizer"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1612186238585
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.el import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1612186241452
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = el_core_news_sm.load()"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1612186245408
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = GreekLemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1612186247839
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadStopWords():\n",
        "    sWords = open('stopWords.txt','r',encoding='utf-8')\n",
        "    sw = set(sWords.read().split('\\n'))\n",
        "    #sw = sw.remove('μη')\n",
        "    sWords.close()\n",
        "    return sw"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1612186252854
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replaceTerm(text):\r\n",
        "    text = text.replace('-banking','banking')\r\n",
        "    text = text.replace('v banking','vbanking')\r\n",
        "    text = text.replace('e banking','ebanking')\r\n",
        "    return text\r\n"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1612186257229
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sw = nlp.Defaults.stop_words\n",
        "#sw = sw|{'εχω','απο','ωστε'}\n",
        "sw = loadStopWords()\n",
        "def remove_ton(text):\n",
        "    diction = {'ά':'α','έ':'ε','ί':'ι','ό':'ο','ώ':'ω','ύ':'υ'}\n",
        "    for key in diction.keys():\n",
        "        text = text.replace(key, diction[key])\n",
        "    return text   \n",
        "def clean_text(text):\n",
        "     #text to string\n",
        "    text = str(text).lower()\n",
        "    text = replaceTerm(text)\n",
        "   # tokenize text and remove puncutation\n",
        "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
        "    # lower text\n",
        "    text = [remove_ton(x) for x in text]\n",
        "    # remove stop words\n",
        "    text = [x for x in text if x not in sw]\n",
        " \n",
        "    #remove quotes\n",
        "    text = [x.replace('quot;','').replace('&quot','') for x in text if x not in ['quot','amp']]\n",
        "    # remove words that contain numbers\n",
        "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
        "    # remove empty tokens\n",
        "    text = [t for t in text if len(t) > 0]\n",
        "    # remove amp & quot\n",
        "    text = [x for x in text if x not in ['quot','amp']]\n",
        "    # remove words with only one letter\n",
        "    text = \" \".join([t for t in text if len(t) > 1])\n",
        "    # lemmatize text\n",
        "    text = \" \".join([lemmatizer(t.text,t.pos_)[0] for t in nlp(text)])\n",
        "   \n",
        "    return(text)"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "gather": {
          "logged": 1612186266296
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# azureml-core of version 1.0.72 or higher is required\n",
        "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "subscription_id = '6ed9d167-b2e6-41b8-9500-35e6df64d9dc'\n",
        "resource_group = 'MLRG'\n",
        "workspace_name = 'erbbimlws'\n",
        "\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
        "\n",
        "dataset = Dataset.get_by_name(workspace, name='vBankingComments')\n",
        "df = dataset.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "gather": {
          "logged": 1612186281016
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612175104032
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['tokenized'] = df['CON_COMMENTS'].apply(clean_text)"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1612186537263
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df.head(1000)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1612174036013
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.fillna('N/A')"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1612186801751
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(min_df = 100,ngram_range = (1,2))"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1612186804507
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_result = tfidf.fit_transform(df['tokenized']).toarray()"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1612186807688
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1612186810915
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_df.columns = [str(x) for x in tfidf_df.columns]"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1612186813533
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = pd.concat([df[['CON_ROW_ID']],tfidf_df],axis=1).melt(id_vars=['CON_ROW_ID'],value_vars = tfidf_df.columns).dropna()"
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1612186819121
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f = df_f[df_f['value']>0]"
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1612186823078
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install openpyxl\r\n",
        "#import openpyxl"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1612176004311
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f[['CON_ROW_ID','variable']].to_excel('vBanking_tokens.xlsx',index = False)\n",
        "#df_f[df_f['value']>0].to_excel('D://Downloads//comments_tokens.xlsx')\n",
        "#df.to_excel('D://Downloads//comments_cleaned.xlsx')"
      ],
      "outputs": [],
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1612186834481
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_f[df_f['variable']=='banking']['CON_ROW_ID'].apply(str)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1612174055112
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[df['CON_ROW_ID'] == 63699307].CON_COMMENTS)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1612174055386
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}